{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents and store them as a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "path = \"../../data/lem\"\n",
    "year = \"2010_2019\"\n",
    "category = \"N_A\"\n",
    "num_topics = 20\n",
    "file_name = year+\"_\"+category+\"_no_names_beletrie\"\n",
    "file_path = path+\"/\"+file_name + \".txt\"\n",
    "\n",
    "def load_books_1000_blocks_from_document(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    books = []\n",
    "    books_info = []\n",
    "    start_tag = '<doc title=\"'\n",
    "    end_tag = '</doc>'\n",
    "    start_index = 0\n",
    "\n",
    "    while True:\n",
    "        book_start = content.find(start_tag, start_index)\n",
    "        if book_start == -1:\n",
    "            break\n",
    "\n",
    "        book_end = content.find(end_tag, book_start)\n",
    "        if book_end == -1:\n",
    "            break\n",
    "\n",
    "        book_text = content[book_start:book_end + len(end_tag)]\n",
    "        book_info = book_text.strip()[5:book_text.index('>') + 1]  # Remove '<doc' and '</doc>'\n",
    "\n",
    "        book_info_list = book_info.split('\" ')\n",
    "        book_info_dict = {}\n",
    "\n",
    "        for item in book_info_list:\n",
    "            key, value = item.split('=')\n",
    "            book_info_dict[key.strip()] = value.strip('\"')\n",
    "\n",
    "        book_content = book_text[book_text.index('>') + 1:-len(end_tag)].strip()\n",
    "        book_content = book_content.split(' ')\n",
    "        length = len(book_content)\n",
    "        CONST = 1000\n",
    "        for i in range(math.ceil(length/CONST)):\n",
    "            i = i*CONST\n",
    "            end = i+CONST if i+CONST < length-1 else length-1\n",
    "            books.append(\" \".join(book_content[i:end]))\n",
    "            books_info.append(book_info_dict)\n",
    "\n",
    "        start_index = book_end + len(end_tag)\n",
    "\n",
    "    return books, books_info\n",
    "\n",
    "books, books_info = load_books_1000_blocks_from_document(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_data = [word_tokenize(doc) for doc in books]\n",
    "\n",
    "# Create a dictionary from the preprocessed data\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    "\n",
    "# Create a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_data]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "passes = 10\n",
    "alpha = 'auto'\n",
    "eta = 'auto'\n",
    "# Train the LDA model\n",
    "# LDA - mixture of topics\n",
    "# Iterative Bayesian proces  \n",
    "lda_model = LdaModel(\n",
    "    corpus=doc_term_matrix,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,  # Number of topics\n",
    "    passes=passes,      # Number of iterations\n",
    "    alpha = alpha, # scalar for a symmetric prior over document-topic distribution\n",
    "    eta = eta\n",
    ")\n",
    "\n",
    "save_path = \"../../data/models/1000 chunk/lda/lda_\" + file_name\n",
    "temp_file = datapath(save_path)\n",
    "\n",
    "lda_model.save(temp_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "from gensim import  models\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "save_path = \"../../data/models/1000 chunk/lda/lda_{num_topics}_topics\".format(num_topics = num_topics) + file_name\n",
    "temp_file = datapath(save_path)\n",
    "\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel.load(temp_file)\n",
    "\n",
    "topic_words = lda_model.print_topics(num_topics = 20, num_words = 20)\n",
    "\n",
    "with open(\"../../data/lda_20_topics_{year}.txt\".format(year = year), \"w\", encoding = 'utf8') as output:\n",
    "    for row in topic_words:\n",
    "        output.write(str(row) + '\\n')\n",
    "print(topic_words)\n",
    "# Visualize the LDA model\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "file_plot = '../../plots/Python/LDA/lda'+ '_' + year + '_' + category + '_'  + str(num_topics) + '_topics' +  '.html'\n",
    "pyLDAvis.save_html(vis, file_plot)\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import  models\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "save_path = \"../../data/models/1000 chunk/lda/lda_{num_topics}_topics\".format(num_topics = num_topics) + file_name\n",
    "temp_file = datapath(save_path)\n",
    "\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel.load(temp_file)\n",
    "\n",
    "# Create the topic-document matrix\n",
    "topic_doc_matrix = lda_model.get_document_topics(doc_term_matrix)\n",
    "\n",
    "# Convert the topic-document matrix to a format that pyLDAvis understands\n",
    "data = []\n",
    "for i, doc_topics in enumerate(topic_doc_matrix):\n",
    "    topic_contributions = [0] * lda_model.num_topics\n",
    "    for topic_id, topic_prob in doc_topics:\n",
    "        topic_contributions[topic_id] = topic_prob\n",
    "    data.append({\n",
    "        'title': books_info[i]['title'],\n",
    "        'author': books_info[i]['author'],\n",
    "        'publisher': books_info[i]['publisher'],\n",
    "        'first_published': books_info[i]['first_published'],\n",
    "        'authsex': books_info[i]['authsex'],\n",
    "        'topic_contributions': topic_contributions\n",
    "        }) \n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient = 'columns')\n",
    "\n",
    "document_name = df['title'][0]\n",
    "info = [df['author'][0], df['publisher'][0], df['first_published'][0], df['authsex'][0]]\n",
    "count = 0\n",
    "topic_distribution = [0 for i in range(num_topics)]\n",
    "td_dict = {}\n",
    "for _, row in df.iterrows():\n",
    "    if row['title'] != document_name:\n",
    "        td_dict[document_name] = info + [(i/count)*100 for i in topic_distribution]\n",
    "        info = [row['author'], row['publisher'], row['first_published'], row['authsex']]\n",
    "        topic_distribution = row['topic_contributions']\n",
    "        document_name = row['title']\n",
    "        count = 1\n",
    "    else:\n",
    "        lists_of_lists = [topic_distribution, row['topic_contributions']]\n",
    "        topic_distribution = [sum(i) for i in zip(*lists_of_lists)]  \n",
    "        count += 1 \n",
    "td_dict[document_name] = info + topic_distribution \n",
    "\n",
    "df_LDA = pd.DataFrame(data = td_dict)\n",
    "df_LDA = df_LDA.T\n",
    "df_LDA.to_excel(\"../../data/topics/lda/lda_{num_topics}_{year}topics.xlsx\".format(num_topics = num_topics, year = year) )\n",
    "print(td_dict)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
